{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061593e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 03:50:29.686144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:29.715139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:29.715721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:29.716910: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-19 03:50:29.744219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:29.744847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:29.744987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:30.338162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:30.338372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:30.338503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 03:50:30.338647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5668 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Dropout,GlobalMaxPool1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "from numpy import random\n",
    "import cv2\n",
    "import pafy\n",
    "import os\n",
    "\n",
    "import datetime as dt \n",
    "from collections import deque\n",
    "from moviepy.editor import *\n",
    "import pafy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import create_dataset\n",
    "\n",
    "labels=np.load('vivit_labels.npy')\n",
    "features=np.load('vivit_features.npy')\n",
    "\n",
    "INPUT_SHAPE = (64,64,64, 3)\n",
    "NUM_CLASSES=len(np.unique(labels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b871062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5432c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "EPOCHS = 60\n",
    "\n",
    "PATCH_SIZE = (8, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#features,labels=create_dataset.create_dataset()\n",
    "#features=np.array(features)\n",
    "#np.save('features.npy',features)\n",
    "#labels=np.array(labels)\n",
    "#np.save('labels.npy',labels)\n",
    "\n",
    "seed_constant = 50\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)\n",
    "\n",
    "\n",
    "\n",
    "labels=to_categorical(labels,num_classes=NUM_CLASSES)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45ce44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb1802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ddf13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "\n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d618a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vivit_classifier(\n",
    "    \n",
    "    \n",
    "    input_shape=INPUT_SHAPE,\n",
    "    transformer_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embed_dim=PROJECTION_DIM,\n",
    "    layer_norm_eps=LAYER_NORM_EPS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    tubelet_embedder=TubeletEmbedding(embed_dim=embed_dim,patch_size=PATCH_SIZE)\n",
    "    positional_encoder=PositionalEncoder(embed_dim=embed_dim)\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = tubelet_embedder(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization and MHSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
    "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
    "            ]\n",
    "        )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb73aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vvit_model=create_vivit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b26fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vvit_model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d68d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 64, 64, 64,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " tubelet_embedding_1 (TubeletEm  (None, 512, 128)    196736      ['input_4[0][0]']                \n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " positional_encoder_1 (Position  (None, 512, 128)    65536       ['tubelet_embedding_1[0][0]']    \n",
      " alEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 512, 128)    256         ['positional_encoder_1[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 512, 128)    66048       ['layer_normalization_17[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 512, 128)     0           ['multi_head_attention_8[0][0]', \n",
      "                                                                  'positional_encoder_1[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 512, 128)    256         ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 512, 128)     131712      ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 512, 128)     0           ['sequential_8[0][0]',           \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 512, 128)    256         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 512, 128)    66048       ['layer_normalization_19[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 512, 128)     0           ['multi_head_attention_9[0][0]', \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 512, 128)    256         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 512, 128)     131712      ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 512, 128)     0           ['sequential_9[0][0]',           \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 512, 128)    256         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 512, 128)    66048       ['layer_normalization_21[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 512, 128)     0           ['multi_head_attention_10[0][0]',\n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 512, 128)    256         ['add_20[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_10 (Sequential)     (None, 512, 128)     131712      ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 512, 128)     0           ['sequential_10[0][0]',          \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 512, 128)    256         ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 512, 128)    66048       ['layer_normalization_23[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 512, 128)     0           ['multi_head_attention_11[0][0]',\n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 512, 128)    256         ['add_22[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_11 (Sequential)     (None, 512, 128)     131712      ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 512, 128)     0           ['sequential_11[0][0]',          \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 512, 128)    256         ['add_23[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " multi_head_attention_12 (Multi  (None, 512, 128)    66048       ['layer_normalization_25[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 512, 128)     0           ['multi_head_attention_12[0][0]',\n",
      "                                                                  'add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 512, 128)    256         ['add_24[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)     (None, 512, 128)     131712      ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 512, 128)     0           ['sequential_12[0][0]',          \n",
      "                                                                  'add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 512, 128)    256         ['add_25[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 512, 128)    66048       ['layer_normalization_27[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 512, 128)     0           ['multi_head_attention_13[0][0]',\n",
      "                                                                  'add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 512, 128)    256         ['add_26[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)     (None, 512, 128)     131712      ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 512, 128)     0           ['sequential_13[0][0]',          \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 512, 128)    256         ['add_27[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 512, 128)    66048       ['layer_normalization_29[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 512, 128)     0           ['multi_head_attention_14[0][0]',\n",
      "                                                                  'add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 512, 128)    256         ['add_28[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 512, 128)     131712      ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 512, 128)     0           ['sequential_14[0][0]',          \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 512, 128)    256         ['add_29[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 512, 128)    66048       ['layer_normalization_31[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 512, 128)     0           ['multi_head_attention_15[0][0]',\n",
      "                                                                  'add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 512, 128)    256         ['add_30[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)     (None, 512, 128)     131712      ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 512, 128)     0           ['sequential_15[0][0]',          \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 512, 128)    256         ['add_31[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['layer_normalization_33[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 4)            516         ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,849,220\n",
      "Trainable params: 1,849,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vvit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a7a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=tf.keras.callbacks.ModelCheckpoint('vvit_saved_model',monitor='val_acc',save_weights_only=False,save_best_only=True,\n",
    "                                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b84efef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vvit_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mvvit_model\u001b[49m\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX_train,y\u001b[38;5;241m=\u001b[39my_train,validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,callbacks\u001b[38;5;241m=\u001b[39m[checkpoint],shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vvit_model' is not defined"
     ]
    }
   ],
   "source": [
    "history=vvit_model.fit(x=X_train,y=y_train,validation_split=0.2,callbacks=[checkpoint],shuffle=1,epochs=40,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e1cf99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vvit_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvvit_model\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(X_test,y_test,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vvit_model' is not defined"
     ]
    }
   ],
   "source": [
    "vvit_model.evaluate(X_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e01678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
